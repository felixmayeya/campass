<link rel="stylesheet" type="text/css" href="css/help.css" />
<div class="countent">
	<ul class="leftBtn menu">
		<a class="leftBtnH" href="javascript:" data-pos="f1">Product Introduction</a>
		<a class="leftBtnTit" href="javascript:" data-pos="a1">Introduction</a>
		<a class="leftBtnTit" href="javascript:" data-pos="a2">Advantages</a>
		<a class="leftBtnTit" href="javascript:" data-pos="a13">Functions</a>
		<!-- <a class="leftBtnTit" href="javascript:" data-pos="a3">了解更多产品套餐</a> -->
		<a class="leftBtnH" href="javascript:" data-pos="f2">Quick Use</a>
		<a class="leftBtnTit" href="javascript:" data-pos="a4">Create a Project</a>
		<a class="leftBtnTit tithide" href="javascript:" data-pos="a5">Upload Data<i class="shou_fang"></i></a>
		<div class="leftBtnSeclect">
			<li><a href="javascript:" data-pos="b1">Upload as Attachment</a></li>
			<li><a href="javascript:" data-pos="b2">Real-time Upload</a></li>
		</div>
		<a href="javascript:" class="leftBtnTit tithide" data-pos="a6">Parsing of Logs<i class="shou_fang"></i></a>
		<div class="leftBtnSeclect">
			<li><a href="javascript:" data-pos="b3">Types and Formats of Logs</a></li>
			<li><a href="javascript:" data-pos="b4">Pre-parsing of Logs</a></li>
		</div>
		<a href="javascript:" class="leftBtnTit tithide" data-pos="a7">Intelligent Search<i class="shou_fang"></i></a>
		<div class="leftBtnSeclect">
			<li><a href="javascript:" data-pos="b5">Search Components and Functions</a></li>
			<li><a href="javascript:" data-pos="b6">Instances of Intelligent Search</a></li>
			<li><a href="javascript:" data-pos="b12">Search Syntax</a></li>
		</div>
		<a href="javascript:" class="leftBtnTit tithide" data-pos="a14">Monitoring and Alarming<i class="shou_fang"></i></a>
		<div class="leftBtnSeclect">
			<li><a href="javascript:" data-pos="b13">Timed automatic monitoring task</a></li>
			<li><a href="javascript:" data-pos="b14">②Automatic monitoring alert</a></li>
		</div>
		<a href="javascript:" class="leftBtnTit tithide" data-pos="a8">Analysis Report<i class="shou_fang"></i></a>
		<div class="leftBtnSeclect">
			<li><a href="javascript:" data-pos="b7">Components and Functions</a></li>
			<li><a href="javascript:" data-pos="b8">Introduction of Analysis Report - Behavior</a></li>
			<li><a href="javascript:" data-pos="b9">Introduction of Analysis Report - Visitor</a></li>
			<li><a href="javascript:" data-pos="b10">Introduction of Analysis Report - Goals</a></li>
			<li><a href="javascript:" data-pos="b11">Introduction of Analysis Report - Request</a></li>
		</div>
		<a href="javascript:" class="leftBtnTit tithide" data-pos="a15">Web Security Analysis Report<i class="shou_fang"></i></a>
		<div class="leftBtnSeclect">
			<li><a href="javascript:" data-pos="b15">SQL Injection</a></li>
			<li><a href="javascript:" data-pos="b16">File Injection</a></li>
			<li><a href="javascript:" data-pos="b17">XSS Attacks</a></li>
			<li><a href="javascript:" data-pos="b18">Web Crawler</a></li>
		</div>
		<a class="leftBtnH" href="javascript:" data-pos="f3">Dictionary</a>
		<a href="javascript:" class="leftBtnTit" data-pos="a9">Logs </a>
		<a href="javascript:" class="leftBtnTit" data-pos="a10">Machine Data</a>
		<a href="javascript:" class="leftBtnTit" data-pos="a11">Project</a>
		<a href="javascript:" class="leftBtnTit" data-pos="a12">Parsing Fields</a>
		<a class="leftBtnH" href="javascript:" data-pos="f4">Contact us</a>
	</ul>
	<div class="swiperBox">
		<div class="part1">
			<h2 id="f1">I. Product Introduction</h2>
			<h3 id="a1">1. Product Introduction</h3>
			<p class="help1">
				CAMPASS is an enterprise-level log data analysis and management platform and provides the high-efficiency and omni bearing one-stop log acquisition, processing and analysis services to help enterprises sufficiently discover the application value of massive log data from websites and other IT systems, improve their management efficiency, optimize their IT operation and maintenance, drive the business growth and obtain more business opportunities and save their costs.
			</p>
			<p class="help1">
				CAMPASS is capable to consolidate several types of log data from different website platforms, servers and systems at a time, is convenient to gather newly generated logs in a real-time manner and therefore help enterprises with fast and centralized log management. Its full-automatic data acquisition, data cleaning, parsing, indexing, structured processing and statistical analysis modeling make any individuals easy to review multi-indicator and multi-dimension visual analysis reports so as to drive enterprises to make optimal decisions based on data. Its full-text log search function can return search results containing hundreds of millions of data within seconds and it supports real-time alarm and can help enterprises to locate the root problems at the earliest time and reduce the system risks.
			</p>
			<p class="help1">
				Based on CAMPASS’ intelligent log data analysis platform, we can also help to customize developments according to different business needs of enterprises. We will use our world-leading technologies of data processing for machine data and natural language, and artificial intelligent algorithms such as machine learning to help enterprises to mine more valuable data, predict potential risks and grasp more opportunities.
			</p>
			<p class="help1">
				CAMPASS is capable to assist IT operation and maintenance technicians, R&D engineers, business marketers and product developers in improving their work efficiency and reduce their investment and cost.
			</p>
			<ul class="helpul1 clearfix">
				<li>
					<p class="help2">Drive your businesses</p>
					<ul class="helpul2">
						<li>Monitor your online business</li>
						<li>Business transactions and conversion analysis</li>
						<li>Precision marketing (e.g. channel, user portrait)</li>
						<li>Refined product development</li>
					</ul>
				</li>
				<li>
					<p class="help2">Operation & Maintenance Monitoring</p>
					<ul class="helpul2">
						<li>Troubleshoot server & application failures</li>
						<li>Analysis on root causes of failure and risk</li>
						<li>Server & IT system performance monitoring</li>
						<li>Website / platform invasion monitoring</li>
					</ul>
				</li>
				<li>
					<p class="help2">Security audit</p>
					<ul class="helpul2">
						<li>Security information and event management </li>
						<li>Compliance audit</li>
						<li>Find advanced persistent threats</li>
						<li>Customized real-time alarms</li>
					</ul>
				</li>
			</ul>
			<div class="arrow_p">
				<p class="help3">Value</p>
				<div class="arrow">&uarr;</div>
				<div class="de">
					Full-text Search&nbsp;&nbsp;Data Visualization&nbsp;&nbsp;Multi-dimension Analysis Report&nbsp;&nbsp;Real-time Alarm
				</div>
				<p class="help3">Application</p>
				<div class="arrow">&uarr;</div>
				<div class="de">
					Real-time and Centralized Acquisition → Structured Processing → Automatic Parsing and Creating Index → Data Modeling <br/> Machine Learning, Self-optimization
				</div>
				<p class="help3">CAMPASS Data Processing Center</p>
				<div class="arrow">&uarr;</div>
				<div class="de">
					Web Server&nbsp;&nbsp;Click Stream&nbsp;&nbsp;System Server&nbsp;&nbsp;ERP · CRM · OLTP&nbsp;&nbsp;Textual Data&nbsp;&nbsp;Social Networking Services&nbsp;&nbsp;IoT Sensor Data&nbsp;&nbsp;Positioning System Data&nbsp;&nbsp;Other Machine Data
				</div>
				<p class="help3">Diversified Data Sources</p>
				<p class="line"></p>
			</div>
			<h3 id="a2">2. Product Advantages </h3>
			<p class="help4">Ease to install, ease to use, powerful functions, available to be used on-premise or cloud-based.</p>
			<ul class="helpul2">
				<li><b>Ease to install and use</b>：It shall take only 5 minutes for configuration and carried out real-time log management with visual interface, without the need of any modification to the system or configuration scripting.</li>
				<li><b>Powerful functions</b>：Rich intelligent search and data visualization functions satisfy multi-dimensional analysis demands. </li>
				<li><b>Diversified application modes</b>：We provide SaaS mode just like using emails, integrate software into hardware mode or on-premise mode.</li>
			</ul>
			<h3 id="a13">3. Functions of the Product</h3>
			<ul class="helpul4">
				<li>Data acquisition and parsing - Centralized management, real-time acquisition, supporting diversified types of log data</li>
			</ul>
			<p class="help1">CAMPASS supports diversified types of log data such as Apache, Tomcat, Syslog, Java, PHP and so on. With the automatic and customized data parsing process, you can easily transform unstructured logs data into structured data and perfect the business intelligence analysis.
			</p>
			<p class="help1">With simple configuration to your server, CAMPASS can easily realize the collection real-time log data from diversified terminals with its stream data processing technologies. Its automated centralized data cleaning, parsing and indexing modes help enterprises in easily managing TB-PB-level massive data.
			</p>
			<ul class="helpul4">
				<li>Automated analysis report - Create correlation between data and obtain more business insights. </li>
			</ul>
			<p class="help1">Able to collect and analyze different types of logs from different departments, different devices, to achieve a comprehensive and real-time analysis of big data. The unique panorama behavior trends charts can better help the enterprises in creating multi-dimensional correlations between products, users, behaviors, time, territories and channels and therefore comprehensively promotive the user experience, product iteration and marketing effects and make the enterprises to obtain more business insights.
			</p>
			<ul class="helpul4">
				<li>Data visualization - there is no need for you to wait before viewing any data charts </li>
			</ul>
			<p class="help1">based on the rich marketing and strategic operation data analysis experience of our data scientist team, CAMPASS embedded with mature statistical data analysis and machine learning models. Multi-dimensional statistical charts can be generated directly after importing the log data. Any one can according to their business needs to view and download visualized reports and easily switch over to other statistical dimension so as to provide data support for any business decisions at the earliest moment.
			</p>
			<ul class="helpul4">
				<li>Fast intelligent search - It helps to search log data just like a search engine</li>
			</ul>
			<p class="help1">It supports full-text log data search. Users have no need to master complicate search syntax or learn to compile scripts but can easily search log data just like a search engine, and even can customize to inquire log data within the specified time range. Our updating algorithm greatly increases the search speed and the search among hundreds of millions of logs can return results within several seconds, greatly increase the operation and maintenance diagnosis efficiency.
			</p>
			<ul class="helpul4">
				<li>Security Information and Event Management (SIEM) - It can find and impede potential threats and attacks and further improve the data security for enterprises.</li>
			</ul>
			<p class="help1">By centralized management and analysis of firewall, network devices and server logs data,  CAMPASS can help enterprises in globally evaluating the overall safety. The upgraded artificial intelligent algorithm of CAMPASS can identify the infiltrative attack mode from analysis the request behavior and therefore help enterprises in early identifying potential security hazards and more effectively impeding security threats.
			</p>
			<p class="help1">(Part of the function needs to open the appropriate module.)</p>
			<p class="line"></p>
			<!-- <h3 id="a3">3. 了解更多产品套餐</h3> -->
		</div>
		<div class="part2">
			<h2 id="f2">II. Instructions for Quick Use</h2>
			<h3 id="a4">1. Create a Project</h3>
			<p class="help1">In CAMPASS log analysis platform, one project means an analysis and search unit. A project supports a complete analysis goal (for example, the goal to analysis log data on specific mobile phone App). A project may contain several data files. Once a certain project is selected, the system may analyze and search all data files under that project at once. If you have several analysis goals, please create projects for them respectively.
			</p>
			<p class="help1">In order to ensure that your uploaded data could be processed correctly and effectively, please confirm that the data under the same project belong to the same type and format of log before you upload them (for example, all data under Project A are logs of standard Apache format). Any data unvested under a project cannot be used for analysis report review and intelligent search.
			</p>
			<p class="help1">You may, in the “Explorer” page, review the project already created. Click the button “Create New Project” and you can create a new project in that page. When you select to delete a project, all the data under that project will be deleted together.
			</p>
			<p class="help1">Deleted projects may be saved in the Recycle for 7 days before they are drastically removed. </p>
			<p class="line"></p>
			<h3 id="a5">2. Upload Data</h3>
			<p class="help1">This section introduces how to upload log files for the purpose to be used for subsequent analysis report review and intelligent search. CAMPASS currently support uploading log data in an attachment mode or uploading real-time generated log data in a script configuration rsyslog mode. The following will introduce in detail the procedures and precautions of the two modes.
			</p>
			<div style="padding-left:30px;">
				<p class="line"></p>
				<h3 id="b1">① Upload as Attachment</h3>
				<p class="help1">The attachment-format upload mode is applicable for stock log data, and the transmission process is based on encrypted secure file transfer protocol (SFTP).</p>
				<p class="help5">Upload Process: </p>
				<p class="help1">Enter the “Data Upload” page, select and append a log file to be uploaded and select a project for the data. If you have not created a project when uploading data, you may temporarily select “Temporarily not create a project” to skip this step but do it later. Only the data for which a project has been ascribed can be used for analysis report review or intelligent search.
				</p>
				<p class="help1">Otherwise, you may, in the “Explorer” page, select one project for which you want to append data to, and then select the item “Data Upload” from the drop-down menu below the “Operation” button under the project to append more data for that project.
				</p>
				<p class="help1">Formats of upload files currently acceptable for CAMPASS include txt, log, json, csv, excel and other uncompressed textual log files or the following compressed log files:.zip, .tar.xz, .xz, .rar, .tar, .tar.gz, .gz, .bz2, .tar.bz2, .z, .tar.z.
				</p>
				<p class="help5">Invalidation / Deletion of Data:</p>
				<p class="help1">
					Data storage time is associated with the “Duration of storage” under your account. Once after the duration of storage expires, the data uploaded by you will become not available for any analysis and search. You may, in the “Resource management” page, browse the “upload time” and “expiration time” of data to know which data is due to expire. The common duration of storage is 30 days, which may be prolonged or shorten by readjusting the type of your package.
				</p>
				<p class="help1">
					If you manually delete the uploaded data within the duration of storage, that data will become invalid immediately and cannot be recovered.
				</p>
				<p class="help1">
					The invalidation and deletion of a certain data is effective for current data file but will not affect the use of other data files under the project. However, any increase or decrease of data will result in the system to recalculate the statistical result, which may lead to more system time consumption.
				</p>
				<p class="help5">
					Precautions relating to data upload:
				</p>
				<p class="help1">
					1. The time spent in uploading and parsing data is directly associated with the size of the data file. It is recommended you to upload a data file not larger than 1GB at a time. Should you have larger data application demand, please contact us and we shall also accept data via CD and HD.
				</p>
				<p class="help1">
					2. While uploading any data, do not shut down the browser or skip to other page, otherwise the upload process may be interrupted. 
				</p>
				<p class="help1">3. The amount of traffic and fee shall be accounted after decompression. You will be noticed if the monthly data allowance has been used up. At any time you may review the used capacity and available capacity in the “Data Upload” page. For more information about capacity package, please contact our business support (E-mail:support@open01.com，TEL: 010-8272 4800).
				</p>
				<p class="line"></p>
				<h3 id="b2">② Real-time Upload</h3>
				<p class="help1">Real-time upload is applicable for real-time collected log data. You may at any time collect newly generated logs and refresh the browser page to review real-time updated statistical analysis results and for intelligent search.
				</p>
				<p class="help1">
					You are reminded that every configuration file can monitor only one log file. If you wish to monitor more log files, please create a configuration file for each log file respectively.
				</p>
				<p class="help5">Uploading procedures: </p>
				<p class="help1">Prior to the following operations, Please confirm the JDK version of your server is 1.7 or above and the cURL utilities have been installed. If not, please contact the system administration of your company.</p>
				<p class="help1">
					<b>Step I: Generate configuration script</b>
				</p>
				<p class="help1">1. Please verify the JDK version of your server：</p>
				<p class="help6">Run the following commands in your server:</p>
				<p class="help6"><span class="highlight">java -version</span></p>
				<p class="help6">If the following content appears：</p>
				<p class="help6 highlight">java version "1.8.0_111"<br />
				Java(TM) SE Runtime Environment (build 1.8.0_111-b14)<br />
				Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode)</p>
				<p class="help6">It indicates that your JDK is V 1.8.0_111 and meet the deployment requirements (make sure that the JDK version is 1.7 or above).</p>
				<p class="help6">If the following content appears：</p>
				<p class="help6"><span class="highlight">bash: java: command not found</span></p>
				<p class="help6">It indicates that the server is not installed JDK, please install it first.</p>
				<p class="help6">
					<b>· Note: JDK installation method:</b>
				</p>
				<p class="help6">1）1, To create the Java installation path (here we use "/usr/java" as the installation example, and version 1.7 as the JDK example):</p>
				<p class="help6 highlight">[root@localhost ~]# mkdir /usr/java<br />
				[root@localhost ~]# cd /usr/java</p>
				<p class="help6">2）Download JDK:</p>
				<p class="help6">Download page：</p>
				<p class="help6"><a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p>
				<p class="help6">3） Extract:</p>
				<p class="help6"><span class="highlight">[root@localhost java]# tar -zxvf jdk-7u79-linux-x64.tar.gz</span></p>
				<p class="help6">4）Set the variables:</p>
				<p class="help6"><span class="highlight">[root@localhost java]# vi /etc/profile</span></p>
				<p class="help6">Add the following content to profile:</p>
				<p class="help6 highlight">
				#set java environment<br />
				JAVA_HOME=/usr/java/jdk1.7.0_79<br />
				JRE_HOME=/usr/java/jdk1.7.0_79/jre<br />
				CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib<br />
				PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin<br />
				export JAVA_HOME JRE_HOME CLASS_PATH PATH
				</p>
				<p class="help6">To make it work:</p>
				<p class="help6"><span class="highlight">[root@localhost java]# source /etc/profile</span></p>
				<p class="help1">
					2. Please check the cURL command
				</p>
				<p class="help6">
				Executing the cURL command in the terminal window:
				</p>
				<p class="help6"><span class="highlight">[root@localhost java]# curl</span></p>
				<p class="help6">If the following content appears, it indicates that the cURL has been installed in your system：</p>
				<p class="help6"><span class="highlight">curl: try 'curl --help' or 'curl --manual' for more information</span></p>
				<p class="help6">If the following content appears, it indicates that system is not installed cURL：</p>
				<p class="help6"><span class="highlight">-bash: curl: command not found</span></p>
				<p class="help6"><b>·Note: Installation method of cURL:</b></p>
				<p class="help6">1）download (here  we use version 7.38.0 as the cURL example)</p>
				<p class="help6">Download page：<a href="https://curl.haxx.se/download.html" target="_blank">https://curl.haxx.se/download.html</a></p>
				<p class="help6">2）Extract:</p>
				<p class="help6"><span class="highlight">tar -xzvf curl-7.38.0.tar.gz</span></p>
				<p class="help6">3）Install:</p>
				<p class="help6 highlight">
				cd curl-7.38.0<br />
				./configure<br />
				make<br />
				make install</p>
				<p class="help6">The cURL’s installation has been finished.</p>
				<p class="help1">3. Fill in configuration information：</p>
				<p class="help6">
				1）Select a project for the data uploaded;
				</p>
				<p class="help6">2）Absolute path of log file：</p>
				<p class="help6">3)  Select log type:</p>
				<p class="help1">
					<b>Step II: Execute configuration script</b>
				</p>
				<p class="help6">1.Copy your configuration script:</p>
				<p class="help6">After the aforesaid configuration is finished, CAMPASS will automatically generate a configuration script for you. Please click the “Copy” button to copy them. </p>
				<p class="help6">2. Execute configuration script: </p>
				<p class="help6">Copy your code to the server and execute as follows:</p>
				<p class="help6 highlight">
				[root@localhost]# curl -d "pattern=%{IP:IP} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:Time}\\]<br />
				\"%{WORD:Method} %{URIPATHPARAM:URL} %{DATA:Protocol}\" %{INT:Status} %{INT:Bytes} \"%{DATA:Referrer}\"<br />
				\"%{DATA:Agent}\"&fields=\"\"&user=26&application=campass&database=open_26_1002568&table=2568&path=/usr/nginx<br />
				/logs/access.txt" http://60.205.152.36:3000/ | sh</p>
				<p class="help6">After executing the command, the following content will be output:</p>
				<p class="help6 highlight">
				% Total % Received % Xferd Average Speed Time Time Time Current<br />
				Dload Upload Total Spent Left Speed<br />
				100 503 0 217 100 286 24 31 0:00:09 0:00:09 --:--:-- 0<br />
				% Total % Received % Xferd Average Speed Time Time Time Current<br />
				Dload Upload Total Spent Left Speed<br />
				100 75.9M 100 75.9M 0 0 262M 0 --:--:-- --:--:-- --:--:-- 263M<br />
				./0c06cd37a6f69afd13277c8bdf8566e5/<br />
				./0c06cd37a6f69afd13277c8bdf8566e5/bin/<br />
				./0c06cd37a6f69afd13277c8bdf8566e5/bin/flume-ng.cmd<br />
				./0c06cd37a6f69afd13277c8bdf8566e5/bin/flume-ng.ps1<br />
				./0c06cd37a6f69afd13277c8bdf8566e5/bin/flume-ng<br />
				./0c06cd37a6f69afd13277c8bdf8566e5/lib/<br />
				./0c06cd37a6f69afd13277c8bdf8566e5/lib/httpclient-4.2.1.jar<br />
				......<br />
				Checking jdk version...<br />
				1.8.0_121<br />
				Jdk version matched<br />
				Data agent log directory checking...<br />
				Data agent log directory created<br />
				Starting data agent...<br />
				Data agent started,Pid = 31562</p>
				<p class="help6">If the following content appears as the last line(In this case, the number of 31562 indicates the process ID, and will vary depending on the process):</p>
				<p class="help6"><span class="highlight">Data agent started,Pid = 31562</span></p>
				<p class="help6">It indicates that the Agent startup successfully!</p>
				<p class="help6">If the following content appears as the last line:</p>
				<p class="help6"><span class="highlight">error: start data agent failed !</span></p>
				<p class="help6">It indicates that the Agent isn’t work.</p>
				<p class="help6">For technical support, please send E-mail to: support@open01.com, or please call: 010-8272 4800.</p>
				<p class="help1"><b>Step III: Automatic real-time data acquisition</b><br />After the configuration finishes, the system will automatically monitor and acquire data. After the first log is obtained, you may review relevant information of that configuration item in the “Resource management” page. </p>
				<p class="help6">
				Uninstall configuration: 
				</p>
				<p class="help6">Enter the path to which you executing the cURL command in Agent configuration.</p>
				<p class="help6">Find the Agent path named by a 32 bit string, such as:</p>
				<p class="help6"><span class="highlight">1dd8f023502b1fd75e4fc643af9a059f</span></p>
				<p class="help6">If the server is configured with multiple Agent, there will be more than one path name. You have to enter the conf  path under those Agents to find the flume.properties file. </p>
				<p class="help6">If you find the following information, you will find the log path for monitoring task configuration:</p>
				<p class="help6"><span class="highlight">a1.sources.r1.filegroups.f1 = /var/log/httpd/access_log</span></p>
				<p class="help6">If the file path that you want to terminate behind the “=”, you can executing the following command under the corresponding Agent path.</p>
				<p class="help6"><span class="highlight">[root@localhost test]# sh stop_agent.sh</span></p>
				<p class="help5">Invalidation / deletion of data:</p>
				<p class="help1">
					The data storage time is associated with the “Duration of storage” under your account. Once after the duration of storage expires, the data uploaded by you will become not available for any analysis and search. You may, in the “Resource management” page, browse the “upload time” and “expiration time” of data to know which data is due to expire. As to real-time uploaded data, only the first log uploaded time is recorded as the “upload time”, and the expire time of each data entry shall be automatically calculated and deleted according to the actual upload time.
				</p>
				<p class="help1">
					If you manually deleted any uploaded data within duration of storage, that data will become invalid immediately.
				</p>
				<p class="help1">
					If the invalidation and deletion of a certain data acts on the current data, the user of other data under the project will not be affected. However, in some model, any increase or decrease of data will cause the system to recalculate the statistical results, which might consume some more time. 
				</p>
			</div>
			<p class="line"></p>
			<h3 id="a6">3. Automatic Parsing of Logs</h3>
			<p class="help1">Correct parsing of logs is the basis to generate multi-dimensional analysis reports.</p>
			<p class="help1">This section introduces the types of logs supported by CAMPASS and the automatic pre-parsing of logs. CAMPASS currently supports such types of logs as Apache, Tomcat, Nginx, IIS and JSON, while it is ceaselessly increasing the types of supported logs. If a log type you wish to analyze is not in the range, please contact us and we shall serve you wholeheartedly.
			</p>
			<div style="padding-left:30px;">
				<p class="line"></p>
				<h3 id="b3">① Types and Formats of Logs</h3>
				<p class="help1">To parse a log is to use the unique data processing of CAMPASS to automatically recognize the log type and format, distinguish and extract the critical information contained in the log according to different log formats. The result from the log parsing is to transform massive mussy non-structured log data into structured data which is available for statistical analysis and easy to understand. The statistical charts of different dimensions in the analysis report are obtained on the basis of structured processing of log data and calculated by using built-in data analysis model.
				</p>
				<p class="help1">Log formats that CAMPASS can automatically recognize are:</p>
				<ul class="helpul2">
					<li>Apache</li>
					<li>Nginx</li>
					<li>JSON</li>
					<li>Linux</li>
					<li>Log4j</li>
				</ul>
				<p class="help1">We shall consecutively increase more log formats that can be automatically recognized. If your logs cannot be correctly recognized and parsed temporarily, please inform us and give us some sample logs.
				</p>
				<p class="help5">Apache/Tomcat</p>
				<p class="help1">Apache/Tomcat log formats supported by CAMPASS are as follows:</p>
				<p class="help1 highlight">
					%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-agent}i\"<br/>%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-agent}i\" \"%{X-Forwarded-For}i\"
				</p>
				<p class="help1">Where, the meanings of various configurations are as follows:</p>
				<p class="help1 highlight">
					%b or %B - Bytes_Size<br/> %h c_ip<br/> %l - email<br/> %r -URI<br/> %s - Status<br/> %t - Timestamp<br/> %{Referer}i - Http_Referer<br/> %{User-agent}i - Http_User_Agent
				</p>
				<p class="help5">Nginx</p>
				<p class="help1">Nginx log formats supported by CAMPASS are as follows: </p>
				<p class="help1 highlight">
					log_format default '$remote_addr - $remote_user [$time_local] "$request" '<br/> '$status $body_bytes_sent "$http_referer" '<br/> '"$http_user_agent" “$http_x_forwarded_for"';<br/>
				</p>
				<p class="help1 highlight">
					log_format main '$remote_addr - $remote_user [$time_local] "$request" '<br/> '$status $body_bytes_sent';<br/>
				</p>
				<p class="help5">Log4j</p>
				<p class="help1">Log4j log formats supported by CAMPASS are as follows: </p>
				<p class="help1 highlight"> %d{ISO8601} %p %t %c.%M - %m%n</p>
				<p class="help5">Linux</p>
				<p class="help1">As for Linux logs, we shall parse them in the standard syslog format. </p>
				<p class="line"></p>
				<h3 id="b4">② Pre-parsing of Logs</h3>
				<p class="help1">After the uploaded data is decompressed, CAMPASS will pre-parse a small part of the log data in some model. The purpose of pre-parsing is to make you more clearly understand the log format and the information it contains.You will receive a notification of the system after your data is uploaded and pre-parsing successfully, please go to the PRE-PARSING PAGEto check the field format. If you think that the pre-parsing field format is inappropriate, you may select a field from the dropdown menu below the header of the parsing sheet. After having checked and confirmed the parsing format, CAMPASS will, according to the field indicated by the header, complete the parsing of the remaining logs uploaded this time. When there are several data files under the same project, it shall be handled according to the parsing format confirmed last time. 
				</p>
				<p class="help1">As for real-time uploaded data, CAMPASS will acquire a small part of log data for pre-parsing. The parsing rules for real-time uploaded logs are consistent with those for attachment upload. The specific meanings of log data parsing fields are as given in <a href="javascript:" id="dic" style="color:#0095d8;">Dictionary - Parsing. </a>
				</p>
				<p class="help1">If any log cannot be parsed due to type or nonstandard or wrong format, you may contact us (E-mail:support@open01.com，TEL: 010-8272 4800) for technical supports. Any log data that cannot be parsed shall not be charged.
				</p>
				<p class="help1">If you logs are of unusual types or nonstandard formats, it is recommended that you provide us a part of sample data in advance and our technicians shall customize to check the parsing fields for your data so as to save your time and obtain more valid and high-quality log analysis results.
				</p>
			</div>
			<p class="line"></p>
			<h3 id="a7">4. Intelligent Search</h3>
			<p class="help1">This section will introduces the function and usage of Intelligent Search. As one of the very important function modules of CAMPASS, Intelligent Search can support any keyword search and customized tag search in any time range and can return the full-text search results within within several seconds<sup>1</sup>. It can help users in quickly filtering and precisely locating associated results.
			</p>
			<p class="help1"><sup>1</sup>A statistical data of search results based on 100 million log data. This time scope is associated with network environment and the size of searched data.</p>
			<div style="padding-left:30px;">
				<p class="line"></p>
				<h3 id="b5">① Search Components and Functions</h3>
				<p class="help1"><b>1.	Project scope:</b><br/> Log data are searched on the project basis, that is to say, the data source to be searched is all the data contained in the project. The project scope may be switched over to other at any time, but one search action can be done in one project scope.
				</p>
				<p class="help1"><b>2.	Time range:</b><br/> CAMPASS supports to search log data in the whole time range. Only if the timestamp of log data is within the selected time range, it can be successfully searched.
				</p>
				<p class="help1"><b>3.	Search and Search in Results:</b><br/> The intelligent search of CAMPASS is an exact match search and supports the use of regular expressions, and you may input your desired field or tag in the search box. If you wish to further screen among the retrieved results, you may select the “Search in Results” function.
				</p>
				<p class="help1"><b>4.	Statistical restuls and views:</b><br/> CAMPASS provides two different search result representations for each search: Event Statistics List and Event Statistics View:
				</p>
				<ul class="helpul2">
					<li><b>Event Statistics List</b>：It displays all search results in a tabular form, including timestamp of log data and original full text of log. The searched fields shall be highlighted in the original log text; you may save and download the event statistics list for storage or use them for deep data mining / analysis in other application.
					</li>
					<li><b>Event Statistics Views</b>：They shall display the statistical views according to the search results, while providing with geographic views based on IP information in searched logs for location. They facilitate you to review and compare the quantity and geographic dimensions of the search results and more precisely locate the root cause of a problem.
					</li>
				</ul>
				<p class="line"></p>
				<h3 id="b6">②	Instances of Intelligent Search</h3>
				<p class="help1">Enter the Intelligent Search page and confirm the searching item. Or, you may switch over to the desired one by using the dropdown menu at any time.</p>
				<img src="img/b1.png" alt="0" class="helpimg toL">
				<p class="help1">Enter your keywords in the search box, select the search time range and then start to search. If the search time range is not within the default time interval, you may select “Custom Range” to customize the starting and ending time for search.
				</p>
				<img src="img/b2.png" alt="0" class="helpimg toL">
				<p class="help1">The search results will be displayed in the forms of Event Statistics Views and Event Statistics List. By default, an event statistics view displays the statistics view and geographic view. The statistics view may, as required, customize diversified types of views, and currently supported views are: Area view, line view, histogram view and scatter plot view. All statistics views support the download function. The event statistics list displays all searched results, including log data timestamp and full text of log; the search field will highlight the original text of the log and support the list export function.
				</p>
				<img src="img/b3.png" alt="0" class="helpimg toL">
				<p class="help1">The search results will be identified in the form of label, and, for each additional search, a new label will be added. However, if you wish to search by using other keyword among the results obtained during a certain search, you may select a certain label, append the keyword in the search box and then click the “Search in Results”.
				</p>
				<p class="line"></p>
				<h3 id="b12">③    Search Syntax</h3>
				<p class="help1">CAMPASS supports the full text search using one or more keywords and supports logical operators, wildcards and other basic regular expressions:</p>
				<p class="help1"><b>1.	Basic Search</b></p>
				<p class="help1">(1) Support the inquiry in the full text of a log using one or more keywords. In this case, the returned results are case-insensitive, for example: </p>
				<p class="help1 highlight"> post</p>
				<p class="help1"> The returned results shall include all logs containing “post” or “POST”.</p>
				<p class="help1">(2) If one inquiry uses several keywords separated by using blank space, the returned results shall be those logs containing any of these keywords, which are case-insensitive. For example:</p>
				<p class="help1 highlight"> kaishu keji </p>
				<p class="help1"> The returned results shall include those logs containing any or several keywords among “kaishu”, “KAISHU”, “keji” or “KEJI”.</p>
				<p class="help1">(3) Phrase Search: When it is necessary to search by using any phrase (all the words in the phrase must be used in the original order and adjacency relation), while the search phrase may be bracketed by using a pair of quotation marks. In this case, the returned results shall be case-insensitive. For example: </p>
				<p class="help1 highlight"> “kaishu keji” </p>
				<p class="help1"> Will return the logs containing “kaishu keji”.</p>
				<p class="help1"><b>2.   Logical operators:</b></p>
				<p class="help1">CAMPASS supports the logical operators AND, OR, NOT and (), which must be capitalized, and the keywords and such operators must be separated by blank space. When searching by using any logical operators, the returned results are case-sensitive.</p>
				<p class="help1">(1) AND, for example:</p>
				<p class="help1 highlight"> term1 AND term2 </p>
				<p class="help1"> Will return the logs containing both “term1” and “term2”</p>
				<p class="help1">(2) OR, for example:</p>
				<p class="help1 highlight"> term1 OR term2 </p>
				<p class="help1"> Will return the logs containing either “term1” or “term2” By default, “OR” may be absent.</p>
				<p class="help1">(3) NOT, for example:</p>
				<p class="help1 highlight"> NOT term1 </p>
				<p class="help1"> NOT, for example:</p>
				<p class="help1">(4) Priorities of logical operators: NOT > AND > OR; the priorities may be changed by using (), where the logical operation in the () will be handled preferentially. For example:</p>
				<p class="help1 highlight"> term1 AND (term2 OR term3) </p>
				<p class="help1"> Will return the logs containing “term1” and “term2” or “term3”.</p>
				<p class="help1"><b>3.   Wildcards:</b></p>
				<p class="help1">(1) Asterisk (*), which matches 0 to more characters. A search using only * will display all logs. For example:</p>
				<p class="help1 highlight"> a*</p>
				<p class="help1"> Will return the logs containing “a”, “ab” or “abc” and other similar words.</p>
				<p class="help1">(2) Question mark (?), which matches 1 character, for example:</p>
				<p class="help1 highlight"> a？</p>
				<p class="help1"> Will return the logs containing “ab”, “ac” or similar words but would not return any log containing such keywords as “a” or “abc”.</p>
				<p class="help1">(3) Plus sign (+). Any keywords behind “+” must appear but the rest may appear or may not appear. For example:</p>
				<p class="help1 highlight"> +term1 term2 </p>
				<p class="help1"> Will return the logs that must contain “term1” but may contain or not contain “term2”</p>
				<p class="help1">(4) Minus sign (-). In the searched results there should be no keyword behind “-”. For example: </p>
				<p class="help1 highlight"> -term1 </p>
				<p class="help1"> Will return the logs not containing “term1”</p>
				<p class="help1"><b>4.   Basic Regular Expressions:</b></p>
				<p class="help1"> CAMPASS also supports the search syntax using lots of regular expressions such as [ ] (range), {n} (n times), {n,m} (n~m times), {n,} (at least n times) and other basic regular expressions. When necessary to use regular expressions for search, please write the search statement in the following formats:</p>
				<p class="help1 highlight"> /regular expression/ </p>
				<p class="help1"> The use of some regular expressions is shown below (for the use rules of more regular expressions, refer to https://en.wikipedia.org/wiki/Regular_expression):</p>
				<p class="help1">(1) [ ]</p>
				<p class="help1 highlight"> /[pb]ost/</p>
				<p class="help1"> Returns any logs contain “post” or “bost”.</p>
				<p class="help1">(2) •{n}, match exactly for n times</p>
				<p class="help1 highlight"> /o{2}/ </p>
				<p class="help1"> It cannot match “do” but “food”.</p>
				<p class="help1">(3) Combined use</p>
				<p class="help1 highlight"> /TP[0-9]{6}/</p>
				<p class="help1"> It will return the logs matching 6 digits behind TP, for example, “TP1234546”.</p>
				<p class="help1">(4) +, different from the wildcard “+”, it is placed behind the keyword.</p>
				<p class="help1 highlight"> /zo+/ </p>
				<p class="help1"> Will return the logs contain “zo” or “zoo” but cannot return any logs containing “z”, that is to say, the matched logs must contain the character before “+” for one time. </p>
				<p class="help1"><b>5.   Search using special characters:</b></p>
				<p class="help1"> Generally, the basic search will match letters, numerics or characters appearing in wildcards and other regular expressions. Additionally, when such special characters as +, -, | |, !, (), { }, [ ], ^, ", ~, *, ?, :, \ and so on appear in the search sentence, they shall be deemed as invalid. If you want any of such special characters, you may use “” to bracket them. </p>
			</div>
			<p class="line"></p>
			<h3 id="a14">5.Monitoring and Alarming:</h3>
				<p class="help1"> This section describes how to set timed automatic monitoring tasks and trigger automatic alert for monitoring results.</p>
				<div style="padding-left:30px;">
				<h3 id="b13">① Timed automatic monitoring task</h3>
				<p class="help1">In order to optimize the service of automate data analysis and management for users, CAMPASS provides the timed automatic monitoring task setting function, which only require users to set the task configuration once. The backend server of CAMPASS will start monitoring the task on a timed basis. You can view the event monitoring results in the Monitoring Dashboard at any time. Additionally, as all monitoring history will be stored in the Monitoring Task Details page, it is convenient for you to review, analyze and manage the event monitoring.</p>
				<p class="help1"><b>1） Generating monitoring tasks:</b></p>
				<p class="help1">Open the page of Log Search and enter the keywords of events you are interested in or concerned about in the search box; click on the Search button, and start the searching task. Click on the button of SAVE AS MONITOR:</p>
				<p class="help1">Save as monitor interface pops up:</p>
				<img src="img/b6.png" alt="0" class="helpimg toL"><br/>
				<img src="img/b7.png" alt="0" class="helpimg toL" style="width:30%;margin-left:10%;cursor:default;">
				<p class="help1"><b>Monitoring task:</b> searching keywords of events;</p>
				<p class="help1"><b>Monitoring program:</b> Data source. To change the monitoring project, please close the popup window, and change the ‘project’  to search again;</p>
				<p class="help1"><b>Monitoring frequency:</b> Interval for triggering a timed automatic monitoring tasks on backend servers, which can be set according to actual situation;</p>
				<p class="help1"><b>Monitoring scope:</b> Time range of the monitoring data, which means you need to search for the data in the given time period indicated by the time range in each search task;When the Monitoring scope equal to Monitoring frequency, the monitoring data will neither be repeated, nor left out;</p>
				<p class="help1"><b>For example:</b><br/>When the Monitoring frequency = 1 h, and the Monitoring scope = 1 h, the monitoring task will be triggered at an interval of 1 hour, and the monitoring data covers the event 1 hour ago up to now;</p>
				<p class="help1">When the Monitoring frequency = 1 h, and the Monitoring scope = 30 min, the monitoring task will be triggered at an interval of 1 hour, the monitoring data covers the event from 30 min  ago to present, while the event from 31 min  to 60 min ago cannot be monitored;</p>
				<p class="help1">When the Monitoring frequency = 1 h, and the Monitoring scope = 2h, the monitoring task will be triggered at an interval of 1 hour, the monitoring data covers the event from 2h ago to present, while the event from 1h ago to present will be monitored twice in two consecutive monitoring tasks;</p>
				<p class="help1">After saving the Settings, the backend server of CAMPASS can trigger time monitoring at the frequency you set, saving your trouble in logging in search interface and manual search every time.</p>
				<p class="help1"><b>2）Viewing the monitoring tasks:</b></p>
				<p class="help1">After saving the monitoring tasks, you can view the real-time monitoring results in the Monitoring dashboard. What’s more, you can click on DETALS button of each task to directly access to the task search results page, and check all original logs of monitoring tasks in the same day.</p>
				<p class="help1">If you want to view the historical results of any monitoring tasks, you can click on HISTORICAL DATA button of this task. All history monitoring task results can be downloaded, which is convenient for you to compare, analyze and share the data trends.</p>
				<p class="help1"><b>3）Deleting the monitoring task:</b></p>
				<p class="help1">You can delete the monitoring tasks no longer needed in Monitoring dashboard or Monitoring task details page, after which the backend server of CAMPASS will no longer  monitor the related events on a timed basis.</p>
				<h3 id="b14">② Automatic monitoring alert</h3>
				<p class="help1">Setting the timed monitoring task is an important step in automatic log management, and the automatic alert for a monitoring task can help you to form a complete closed loop of data monitoring management. According to the monitored contents, you can customize the  conditions for triggering the alert. For each trigged task, CAMPASS will send an E-mail automatically to inform you timely.</p>
				<p class="help1"><b>1）Setting alert information:</b></p>
				<p class="help1">In theSave as monitor pop-up window, check the option of ‘Send E-mail to’, and fill in the E-mail address where you want to receive the notice;</p>
				<img src="img/b5.jpg" alt="0" class="helpimg toL" style="width:30%;margin-left:10%;cursor:default;">
				<p class="help1"><b>Triggering conditions:</b></p>
				<p class="help1">CAMPASS currently supports event count alert and baseline comparison alert:</p>
				<p class="help1"><b>Event count alert:</b> Start timed search task based on monitoring content on a regular basis; when the search results are reached a certain threshold value, the alert will be triggered.</p>
				<p class="help1"><b>Baseline comparison alert:</b> The triggering conditions of baseline comparison alert are more flexible. The alert can be triggered when the value is higher than or lower than a certain threshold value.</p>
				<p class="help1"><b>2）Management of alert E-mail:</b></p>
				<p class="help1">If you don't want to receive the alert E-mail in a certain period of time, but hope the timed monitoring tasks are still carried out, you can temporarily disable the alert notification E-mail function, which can be recovered whenever you want to. The only thing you need to do is to select the TURN ON or TURN OFF button in Monitoring dashboard.</p>
			</div>
			<p class="line"></p>
			<h3 id="a8">6. Analysis Report</h3>
			<p class="help1">This section introduces the function and usage of analysis report. Different from common log management tools, Analysis Report is one of the very distinctive function modules of CAMPASS. Based on the structured data after parsing of logs, CAMPASS is incorporated with several mature statistical analysis models and algorithms enable users to review the statistical analysis results of lots of indicators directly from several dimensions, which greatly improve the business and operation data processing efficiency and provide great support for decision makers.
			</p>
			<div style="padding-left:30px;">
				<p class="line"></p>
				<h3 id="b7">Components and Functions</h3>
				<img src="img/b4.png" alt="0" class="helpimg toL">
				<p class="help1"><b>Project scope: </b></p>
				<p class="help1">Log data are statistically analyzed on the basis of project, that is to say, the data source to be analyzed are all the data contained in the project. One project scope may be switched over to the other at any time, but each analysis can be conducted only in the range of one project.
				</p>
				<p class="help1"><b>Time range: </b></p>
				<p class="help1">CAMPASS supports the statistical analysis of log data in all time ranges, and only if the timestamp is within the selected time range, the log data shall be incorporated into the statistics. If the analyzed time range is not in the default time interval, the user may select the “Custom Range” to customize the starting and ending time for the analysis.
				</p>
				<p class="help1"><b>Analysis report: </b></p>
				<p class="help1">As the most important part of this module, it is to display the changes of several indicators at different dimensions in the form of views. You may click “View Data” on the upper right of the chart to review the event statistics list of that chart. If the statistical data is real-time, you may click the “Add to Dashboard” to add the current chart into the work dashboard in the Home Page, thus, each time when you log in, you can see the real-time statistical analysis report as early as possible.
				</p>
				<p class="help1">For each statistical view, CAMPASS additionally provides very distinctive “Panoramic Comparison Trend View”, which helps you more clearly to compare the change tendency of each indicator and dimension in different time ranges, quickly identify abnormality, more effectively evaluate business effect, iterate products and find potential threats.
				</p>
				<p class="help1"><b>Overview of Indicators: </b></p>
				<p class="help1">It can provide you with the statistical values of a key indicator and the variation of that indicator comparative to the moving base and therefore help you clearly understand the indicator variation trend.</p>
				<p class="help1">An analysis report is composed of four modules including behavior analysis, visitors analysis, goals analysis and request analysis and totally 30 statistical graphs and charts. The following will introduce these modules, graphs and charts respectively.
				</p>
				<p class="line"></p>
				<h3 id="b8">①	Introduction of Analysis Report - Behavior</h3>
				<p class="help6">This module is to give the perspective of access behavior from statistically and analysis the log data, including: </p>
				<p class="help5">1. Page / Path View:</p>
				<ul class="helpul4">
					<li>Overview:</li>
				</ul>
				<p class="help6">It is to count up all the access requests of users. This part is an analysis based on URI field. When the information recorded in the original log is page view, the statistical result shall be total page view. When the information recorded in the original log is access request path, the statistical result shall be total path view.
				</p>
				<ul class="helpul4">
					<li>Distribution:</li>
				</ul>
				<p class="help6">It is to represent the access requests in a map according to the IP information recorded in logs, which is a thermodynamic diagram.</p>
				<ul class="helpul4">
					<li>Ranking:</li>
				</ul>
				<p class="help6">To show the top 50 frequency pages/paths among all access requests. When the information recorded in the original log is page view, the statistical result shall be total page view. When the information recorded in the original log is access request path, the statistical result shall be total path view.
				</p>
				<p class="help6">You can select one page/path to see the further time trajectory of this specific page/path access.</p>
				<ul class="helpul4">
					<li>Proportion：</li>
				</ul>
				<p class="help6">The statistical rules are consistent with those of Ranking. This view is a percentage diagram, facilitating the comparative evaluation from different points of view.
				</p>
				<p class="help5">2. Time on Page / Path:</p>
				<ul class="helpul4">
					<li>Ranking:</li>
				</ul>
				<p class="help6">To show the top 50 longest retention pages/paths among all access requests.</p>
				<p class="help6">Calculate the lasting time of each access request, i.e. the time range between two access requests. In some cases, after triggering a request, the user might leave and open other browser or switch over to other tab page, having no further action for long time, such action that opens a page but has no actual interaction with the opened page should be excluded during statistics. Therefore, in this part, only the case where the time range between two requests is ≤30min will be incorporated into statistics. When an access request is the last operation before the visitor leaves the website, it is impossible to calculate the time range since there is no further request to occur, thus these data shall not be incorporated into the statistics.
				</p>
				<ul class="helpul4">
					<li>Proportion：</li>
				</ul>
				<p class="help6">The statistical rules are consistent with those of “Ranking”. This view will display the data in the form of area percentage diagram to facilitate the comparative evaluation from different points of view.
				</p>
				<p class="help5">3. Traffic Sources:</p>
				<ul class="helpul4">
					<li>Ranking:</li>
				</ul>
				<p class="help6">To show the top 50 pages/paths that are most frequently. You can select one page/path to see the further time trajectory of this specific page/path access.
				</p>
				<p class="help6">An access request source is the previous page/path of the current request, i.e., from where the user skip to the current page/path. For those from enter URL, skip from the inside of the website,  counted up as “Direct Traffic”. For any access via a certain outside website, the main domain of the outside website shall be used for statistics.
				</p>
				<ul class="helpul4">
					<li>Proportion:</li>
				</ul>
				<p class="help6">The statistical rules are consistent with those of “Ranking”. Such view shall display the data in the form of area percentage diagram to facilitate the comparative evaluation from different points of view.
				</p>
				<p class="line"></p>
				<h3 id="b9">②	Introduction of Analysis Report -Visitor</h3>
				<p class="help6">This module is to give the perspective of access visitor from statistically and analysis the log data, including:</p>
				<p class="help5">1. This module is to give the perspective of access visitor from statistically and analysis the log data, including:</p>
				<ul class="helpul4">
					<li>Overview：</li>
				</ul>
				<p class="help6">It refers to all non-repeated IP from all access requests. The “New IP” refers to the IP appearing within the specified statistical time range for the first time among all independent IPs.
				</p>
				<ul class="helpul4">
					<li>Distribution：</li>
				</ul>
				<p class="help6">According to the IP information recorded in logs, represent independent IP data in a map, which is a thermodynamic diagram.</p>
				<ul class="helpul4">
					<li>Ranking：</li>
				</ul>
				<p class="help6">To show the top 50 most frequently access-requested IPs. You can select one IP to see the specific access request occurrence time trajectory of that IP.</p>
				<ul class="helpul4">
					<li>Proportion：</li>
				</ul>
				<p class="help6">The statistical rules are consistent with those of “Ranking”. This view shall display the data in the form of area percentage diagram to facilitate the comparative evaluation from different points of view. </p>
				<p class="help5">2. Operating System: </p>
				<ul class="helpul4">
					<li>Ranking：</li>
				</ul>
				<p class="help6">To show the top 50 operating systems that appear the most frequently among all the access requests, including the PC and mobile operating systems, commonly including Windows10, Windows8, Windows7, Mac OS X, Android and so on. This data records the operating systems used by visitors and is very helpful for you to describe the user portrait, refined product development and identify any abnormalities caused by operating systems.
				</p>
				<ul class="helpul4">
					<li>Proportion：</li>
				</ul>
				<p class="help6">The statistical rules are consistent with those of “Ranking”. This view displays the data in the form of area percentage diagram to facilitate the comparative evaluation from different points of view. </p>
				<p class="help5">3. Browsers:</p>
				<ul class="helpul4">
					<li>Ranking：</li>
				</ul>
				<p class="help6">To show the top 50 browsers that appear the most frequently among all access requests, commonly including chrome, safari, Firefox, IE and so forth. The statistics of user browsers has vital influence on software development and product operation. For example, if being aware that users of a certain product are commonly using a certain browser, the developers may focus on configuring the system for that browser and the user portrait will be more accurate.
				</p>
				<ul class="helpul4">
					<li>Proportion：</li>
				</ul>
				<p class="help6">The statistical rules are consistent with those of “Ranking”. This view shall display the data in the form of area percentage diagram to facilitate the comparative evaluation from different points of view. </p>
				<p class="line"></p>
				<h3 id="b10">③	Introduction of Analysis Report - Goals</h3>
				<p class="help1">The conversion rate analysis is to represent the conversion effect of each step in the funnel plot chart so as for you can more effectively evaluate the effect of economic performance, analyze key steps affecting such conversion and identify customer loss problems and nodes from log data analysis, and therefore help to improve the conversion performance.</p>
				<p class="help1">The procedures to set are as follows:</p>
				<p class="help1"><b>Step 1: Set up conversion procedures:</b></p>
				<p class="help1">If it is the first time for you to use this function, please set up the conversion procedures. The method is to go to the Goals page——Custom process, complete the information of steps, corresponding URLs of each step, and add corresponding descriptions and save it.</p>
				<p class="help1"><b>Step 2: Generate conversion rate funnel: </b></p>
				<p class="help1">After the conversion procedures are set up, the system will automatically extract and process relevant data to generate the conversion rate funnel plot. You may switch over to other time range to review the conversion rate views of different time segments. Or, you may further analyze the differences of conversion rates from different dimensions such as time, region, browser, operating system, where:</p>
				<ul class="helpul4">
					<li>View the Dimension of Time:</li>
				</ul>
				<p class="help1">Review the conversion rate funnel plots of different time points in the selected time range. This function helps you to find out the conversion rate difference due to time difference.</p>
				<ul class="helpul4">
					<li>View the Dimension of Region:</li>
				</ul>
				<p class="help1">Review the conversion rate funnel plots of different regions within the selected time range. This function helps to find the conversion rate difference due to geographic difference. </p>
				<ul class="helpul4">
					<li>View the Dimension of Browser: </li>
				</ul>
				<p class="help1">Review the conversion rate difference caused by different browsers within the selected time range.</p>
				<ul class="helpul4">
					<li>View the Dimension of  Operating System: </li>
				</ul>
				<p class="help1">Review the conversion rate difference caused by different operating systems within the selected time range. </p>
				<p class="line"></p>
				<h3 id="b11">④	Introduction of Analysis Report - Request</h3>
				<p class="help6">This module is to give the perspective of access request action from statistically and analysis the log data, including:</p>
				<p class="help5">1. HTTP Codes:</p>
				<ul class="helpul4">
					<li>Overview：</li>
				</ul>
				<p class="help6">
					It is to count up the responses of website server to access requests, where:
					<br/> 1）Status codes beginning with 1 stand for INFO, meaning that the requests have been accepted and need further processing;
					<br/> 2）Status codes beginning with 2 stand for SUCCESS, meaning that the requests have been successfully received, understood and accepted by the server;
					<br/> 3）Status codes beginning with 3 stand for RELOCATION, meaning that the client is required to execute further operation before the request could be finished;
					<br/> 4）Status codes beginning with 4 stand for REQUEST ERROR, meaning that an error may occur at the client end, hindering the processing of the server;
					<br/> 5）Status code beginning with 5 or 6 stand for SERVER ERROR, meaning that there is a server error or abnormality in the processing course or the server may be aware that current software and hardware resources are insufficient to finish the request processing.
					<br/> (For more information about HTTP response status codes, please refer to W3C
					(<a href="http://www.w3school.com.cn/tags/html_ref_httpmessages.asp" target="_blank" style="color:#0095d8">http://www.w3school.com.cn/tags/html_ref_httpmessages.asp</a>）and RFC 2616（<a href="https://tools.ietf.org/html/rfc2616" target="_blank" style="color:#0095d8">https://tools.ietf.org/html/rfc2616</a>））
				</p>
				<ul class="helpul4">
					<li>Frequency：</li>
				</ul>
				<p class="help6">Review the response status of access requests at different time points.</p>
				<ul class="helpul4">
					<li>Ranking on Page/Path:</li>
				</ul>
				<p class="help6">Screen those most frequently access request paths possible to cause a certain response status. This chart helps to screen abnormal access paths or judge crawler accesses. After selecting a certain path, you may click to further analyze the specific occurrence time trajectory of a certain response status caused by that the path.</p>
				<ul class="helpul4">
					<li>•Ranking on IP: </li>
				</ul>
				<p class="help6">Screen those most frequently access request IPs causing a certain response status. This chart helps to identify suspicious IPs. When a certain IP is selected, you may click to further analyze the specific occurrence time trajectory of a certain response status caused by that IP.</p>
				<p class="help5">2. Data Transfer: </p>
				<ul class="helpul4">
					<li>Overview：</li>
				</ul>
				<p class="help6">It is to count up the data volume to be obtained from or sent to the server due to an access request. The types of access requests hereto include GET, POST and so on.</p>
				<ul class="helpul4">
					<li>Distribution:</li>
				</ul>
				<p class="help6">According to the data volume exchanged with the server, represent the data volume in a map, which is a thermodynamic diagram.</p>
				<ul class="helpul4">
					<li>Ranking on Page/Path:</li>
				</ul>
				<p class="help6">Screen those access request paths to interactive more data with the server. Excessive data exchange may affect the performance of the website. When finding any abnormal path, special check should be taken. When selecting a certain path, you may click to further analyze the data volume exchanged along that path at different time points.</p>
				<ul class="helpul4">
					<li>Ranking on IP:</li>
				</ul>
				<p class="help6">Screen those access request IPs possible to exchange more data with the server. This chart helps to identify suspected IPs.</p>
				<p class="help5">3. Request Type: </p>
				<ul class="helpul4">
					<li>Ranking：</li>
				</ul>
				<p class="help6">Screen those most frequent access request types. </p>
				<ul class="helpul4">
					<li>Proportion：</li>
				</ul>
				<p class="help6">The statistical rules are consistent with those of “Ranking”. This view will display the data in the form of area percentage diagram to facilitate the comparative evaluation from different points of view.</p>
			</div>
			<p class="line"></p>
			<h3 id="a15">7. Web Security Analysis Report</h3>
			<p class="help1">For the enterprises operating websites, portals, providing online services and online transaction, the importance of web security is self-evident. The events that have occurred or influenced security can be root and retrieved through server logs, which can also help find more efficient and effective solutions.</p>
			<p class="help1">However, is it possible for the enterprises to  predict the potential safety hazard and prevent the attacks through early action before any damage occurs? The answer is yes. For the server logs can record information such as origination and operation behavior, with the help of artificial intelligence algorithm, we can identify the "unsafe" access, and present it to the operation administrators or someone in charge of network security.</p>
			<p class="help1">CAMPASS can effectively recognize more than 95% of the Web application attacks1, including SQL injection (SQLi, 48.83%), local file inclusion (LFI, 39.97%), cross-site scripting attack (XSS, 6.18%), and remote file inclusion (RFI, 2.11%).(Statistics from 2016 analysis report of Akamai.)</p>
			<div style="padding-left:30px;">
				<h3 id="b15">①	Introduction of Analysis Report - SQL Injection</h3>
				<p class="help1">SQLi refers to a type of attack aiming at stealing the data from database by inserting SQL commands in web form or query string on page, taking advantage of the vulnerabilities in web pages, phishing the web application server to perform malicious SQL command.</p>
				<p class="help1">Some malicious SQLi attacks can raise the risk of illegal operation of the database, stealing all sensitive information, and injecting Trojan; in the most severe cases, the hackers can get part or all of the web server permissions, compromising the Web pages or servers.</p>
				<p class="help1">CAMPASS’ unique algorithm can effectively identify the metadata of SQLi based on the characteristics of SQLi and SQL syntax characteristics. Through analyzing the field of Query in web log, it can check if the Query field contains the SQLi metadata and decide whether the log contains SQLi attacks.</p>
				<ul class="helpul4">
					<li>Overview：</li>
				</ul>
				<p class="help1">Analysis the unconventional SQLi attacks in  the designated time range, which can represent the risk of the SQL attacks on web sites in designated time range.</p>
				<ul class="helpul4">
					<li>Ranking on IP:</li>
				</ul>
				<p class="help1">Screen out the TOP50 source IPs causing unconventional SQLi frequency in all access requests. Through this chart, the administrators in charge of security can conveniently and efficiently locate the risk source, and take the corresponding measures according to the degree of severity.</p>
				<ul class="helpul4">
					<li>Ranking on Paths:</li>
				</ul>
				<p class="help1">Screen out the top paths / pages most frequently under unconventional SQLi attacks. Through this chart, the administrators in charge of security can accurately locate the pages on website vulnerable to attacks, and enhance the security level or protective measures for the related pages on website.</p>
				<ul class="helpul4">
					<li>Success or Failure:</li>
				</ul>
				<p class="help1">This  chart shows the different results of the unconventional SQLi, i.e. which attacks succeed (usually such attacks are more threatening), which attacks are redirected, which attacks are blocked. Through this chart, the IT operation administrator can fully understand the consequences of attacks and the effect of security measures of website according to a final results of attacks, and give priority to dealing with the successful attacks.</p>
				<h3 id="b16">②	Introduction of Analysis Report - File Injection</h3>
				<p class="help1">The file inclusion vulnerability refers to the web page attacks launched by the  local or remote malicious files imported via INCLUDE FUNCTION of web pages.</p>
				<p class="help1">The main threat of file inclusion vulnerability include implanting malicious Trojan files, viewing password confidential documents, accessing account and permissions, etc., which can lead to disclosure of important documents or information.</p>
				<p class="help1">CAMPASS' unique algorithm can identify the metadata and locations of file inclusion attacks in web log based on the characteristics of file inclusion injection. By parsing the related fields in web log, it can identify whether the file contains file inclusion injection metadata, and thereby determine whether the website has unconventional file inclusion vulnerabilities.</p>
				<ul class="helpul4">
					<li>Overview:</li>
				</ul>
				<p class="help1">Analysis the  number of potential File inclusion attacks in the designated time range, which can reflect the severity of file inclusion attacks against the website in designated time range.</p>
				<ul class="helpul4">
					<li>Ranking on IP:</li>
				</ul>
				<p class="help1">Screen out the TOP50 source IPs of  file inclusion of highest frequency in all access requests. Through this chart, the administrators in charge of security can conveniently and efficiently locate the risk source, and take the corresponding measures according to the degree of severity.</p>
				<ul class="helpul4">
					<li>Ranking on Paths:</li>
				</ul>
				<p class="help1">Screen out the top paths / pages most frequently under file inclusion attacks. Through this chart, the administrators in charge of security can accurately locate the pages on website vulnerable to attacks, and enhance the security level or protective measures for the related pages on website.</p>
				<ul class="helpul4">
					<li>Success or Failure:</li>
				</ul>
				<p class="help1">This  chart shows the different results of the potential file inclusion attack, i.e. which attacks succeed (usually such attacks are more threatening), which attacks are redirected, which attacks are blocked. Through this chart, the IT operation administrator can fully understand the consequences of attacks and the effect of security measures of website according to a final results of attacks, and give priority to dealing with the successful attacks.</p>
				<h3 id="b17">③	Introduction of Analysis Report - XSS Attacks</h3>
				<p class="help1">Cross-site scripting attack (known as XSS or CSS for short) is a common attack against vulnerabilities in web program. The principle of which is the attacker inputs (uploads) the malicious HTML codes to websites which have XSS vulnerabilities; when other users browse the website, this HTML code will automatically execute so as to achieve the attack.</p>
				<p class="help1">The main threats of XSS include stealing the user account information, destructing web page structure, redirecting to other sites, etc. XSS is a harmful attack posing severe threats to website users.</p>
				<p class="help1">CAMPASS’ unique algorithm can identify the metadata and locations of XSS attacks based on the characteristics of XSS attacks. By parsing the related fields in Web log, it can identify whether the file contains XSS metadata, and thereby determine whether the website is under XSS attacks.</p>
				<ul class="helpul4">
					<li>Overview:</li>
				</ul>
				<p class="help1">Analysis the number of potential XSS attacks in the designated time range, which can reflect the severity of XSS attack risk against the website in designated time range.</p>
				<ul class="helpul4">
					<li>Ranking on IP:</li>
				</ul>
				<p class="help1">Screen out the TOP50 source IPs of XSS attacks of highest frequency in all access requests. Through this chart, the administrators in charge of security can conveniently and efficiently locate the risk source, and take the corresponding measures according to the degree of severity.</p>
				<ul class="helpul4">
					<li>Ranking on Paths:</li>
				</ul>
				<p class="help1">Screen out the top paths/pages most frequently under XSS attacks. Through this chart, the administrators in charge of security can accurately locate the pages on website vulnerable to attacks, and enhance the security level or protective measures for the related pages on Website.</p>
				<ul class="helpul4">
					<li>Success or Failure:</li>
				</ul>
				<p class="help1">This  chart shows the different results of XSS attacks, i.e. which attacks succeed (usually such attacks are more threatening), which attacks are redirected, which attacks are blocked. Through this chart, the IT operation administrator can fully understand the consequences of attacks and the effect of security measures of website according to a final results of attacks, and give priority to dealing with the successful attacks.</p>
				<h3 id="b18">④	Introduction of Analysis Report - Web Crawler</h3>
				<p class="help1">The web crawler is a type of program or script automatically searching and accessing webpage information based on certain rules, which has been widely applied to the Internet.
For the marketing and product design personnel, it is conducive to exposure and publicity of website, products and activities by  attracting high-quality crawlers (such as mainstream search engines).</p>
				<p class="help1">However, on the other hand, some malicious crawler is likely to cause excessive consumption of the web server resources, incurring threats to the network bandwidth and computing resources. A large number of malicious crawlers could prevent the web server from providing normal services, thus affecting the normal access to such website. Some malicious users can also steal sensitive information for improper purposes with web crawlers. Thus it is quite important to correctly identify web crawler and access user behavior for enterprise’s marketing, product design, operation and network security personnel.</p>
				<p class="help1">The mainstream crawler recognition software identifies the crawler through the User Agent field in the log, but many malicious crawlers will disguise themselves by modifying the User Agent field, so as to prevent the identification of the software.</p>
				<p class="help1">CAMPASS' unique intelligent algorithm can capture the crawler events through three layers of identification mechanism:</p>
				<p class="help1">The first identification layer: Automatically constructed keyword database for crawler User Agent, which can parse the User Agent field in web log to see if it contains the crawler-related keywords;</p>
				<p class="help1">The second identification layer: Identify the crawler in disguise based on the User Agent fields and access behavior modes;</p>
				<p class="help1">The third identification layer: It is the artificial intelligence identification layer, which can dynamically determine the access frequency of normal visitors  according to the analysis of website access behavior pattern, thus dynamically judging the behavior of crawlers with the pattern recognition technology.</p>
				<ul class="helpul4">
					<li>Overview:</li>
				</ul>
				<p class="help1">Analysis the number of crawler accesses and non-crawler accesses in the designated time range, which can reflect the behavior patterns of machine (crawler) accesses and human (non-crawler) accesses in the designated time range.</p>
				<ul class="helpul4">
					<li>Ranking on IP:</li>
				</ul>
				<p class="help1">Screen out the TOP50 crawler IPs of highest crawling frequencies. Through this chart, the administrators in charge of security can effectively and efficiently identify the access frequency of regular / malicious crawlers, promptly locating the crawlers, and take the corresponding measures according to the degree of severity.</p>
				<ul class="helpul4">
					<li>Ranking on Paths:</li>
				</ul>
				<p class="help1">Screen out the top paths / pages most accessed by the crawlers. Through this chart, the marketing personnel can well know if the the target path / page has been accessed by the target crawler (such as major search engines), and the IT operation personnel in charge of website can accurately locate the pages on website vulnerable to attacks of malicious crawler, and enhance the security level or protective measures for the related pages on Website.</p>
				<ul class="helpul4">
					<li>Success or Failure:</li>
				</ul>
				<p class="help1">This chart shows the different results of crawler behavior, i.e. which crawler behavior succeeds, which crawler behavior is redirected, and which crawler behavior fails. Through this chart, the IT operation personnel can fully understand if the target crawlers are attacked to the website, or if the website is under successful attacks from malicious crawlers, thus taking security measure more precisely and giving priority to dealing with the ulterior crawler events.</p>
			</div>
		</div>
		<div class="part3">
			<p class="line"></p>
			<h2 id="f3">III. Dictionary</h2>
			<h3 id="a9">1.	Logs </h3>
			<p class="help1">During the runtime, any network device, system, sensor, service program and so on will generate some event records that are generally called “logs”. Logs are an atypical machine data recording lots of information including IP addresses of server / client, request date / time, requested page, HTTP codes, request bytes, user events, agent information and so on. The mining analysis of log data helps effectively supporting the management of website service, the operation and maintenance of system server and the making of marketing decisions and so on.
			</p>
			<p class="help1">Reference Source: <br/> 1. Wikipedia
			</p>
			<p class="line"></p>
			<h3 id="a10">2.	Wikipedia</h3>
			<p class="help1">Machine data are some activity records automatically generated by digital devices during the operation. Machine data can, in a real-time and automatic manner, record D operations executed by A device for C object within B time. Such records will be continuously generated as the time goes on and become the effective support for future audit, investigation and research, identifying problems and looking for solutions as well as powerful IT operation & maintenance and auxiliary marketing tools. Effective management of machine data is a new service demand for the development of Internet of Things (IoT).
			</p>
			<p class="help1">Reference Source: <br/> 1. Wikipedia<br/> 2. World Internet Standards Organization W3C
			</p>
			<p class="line"></p>
			<h3 id="a11">3.	Project</h3>
			<p class="help1">In Langlu log analysis, a project is an analysis and search unit. A project supports a complete analysis goal (for example, the log analysis on specific mobile phone App). A project may contain several data files. Once a certain project is selected, the system may analyze and search all data files under that project at once. Any data not belonging to any project cannot be used for analysis report review and intelligent search. If you have several analysis goals, please create projects for them respectively.
			</p>
			<p class="line"></p>
			<h3 id="a12">4.	Parsing of Meanings of Fields</h3>
			<ul class="helpul3">
				<li>1. <b>sc-win32-status</b>：It is a Windows status code. When the status is “Successful Completion”, this code shall be 0. The meanings of other common status codes are as follows:
					<p class="help1">
						1) - Function incorrect<br/> 2) - System fails in finding the specified file<br/> 3) - System fails in finding the specified path<br/> 4) - System cannot open the file<br/> 5) - Access refused<br/> 6) - Handle invalid<br/> 7) - Memory control block damaged<br/> 8) - Memory space insufficient, failing in processing this command<br/> 9) - Memory control block address invalid<br/> 10) - Environment incorrect<br/> 11) - Attempt to load a program of incorrect format<br/> 12) - Access code invalid<br/> 13) - Data invalid <br/> 14) - Memory space insufficient, failing in finishing this operation<br/>
						15) - System cannot find specified driver
						<br/> 16) - Cannot delete the directory<br/> 17) - System cannot move the file to different driver<br/> 18) - No more files<br/> 19) - Media write-protected<br/> 20) - System cannot find specified device<br/> 21) - Device not ready<br/> 22) - Device not identify this command<br/> 23) - Wrong data (Cyclical redundancy check)<br/> 24) - The program sent a command of incorrect length<br/> 25) - Drive cannot find specified area or track on the diskette<br/> 26) - Cannot access specified diskette or floppy disk<br/> 27) - Drive cannot find the requested sector<br/>	28) - The printer is out of paper<br/> 29) - System cannot write in specified device<br/> 30) - System cannot read data from the specified device<br/> 31) - The device connected to the system plays no role<br/> 32) - Other program is using this file. Process cannot be accessed <br/>
						 33) - Other program already locked portion of the file. Process cannot be accessed<br/> 36) - Opened too many files for sharing<br/> 38) - End of file<br/> 39) - Disk full<br/> 50) - Request not supported<br/> 51) - Windows cannot find the network path. Confirm the network path is correct and the destination computer is not busy or already shut down. If Windows still cannot find the network path, contact the network administrator.
						<br/> 52) - Connection fails due to namesakes. Go to “System” in “Control panel” to rename the computer. <br/> 53) - Fail in finding network path<br/> 54) - Network busy<br/> 55) - Specified network resource or device no longer available<br/> 56) - Network BIOS command restriction reached<br/> 57) - Network adapter hardware error<br/> 58) - Specified server cannot run the requested operation<br/> 59) - Unexpected network error occurs<br/> 60) - Remote adapter incompatible<br/> 61) - Printer queue full <br/>	62) - No server space to store the file waiting to be printed<br/> 63) - File waiting to be printed has been deleted<br/> 64) - Specified network name no longer available<br/> 65) - Network access refused<br/> 66) - Type of network resource incorrect<br/> 67) - Network name not found<br/> 68) - Exceed the name limit for local computer network adapter<br/> 69) - Exceed the network BIOS session limit <br/> 70) - Remote server suspended or being started<br/> 71) - Reaching the maximum links of computer, unable to be connected to this computer<br/> 72) - Specified printer or disk device suspended
						<br/>	80) - The file exists<br/> 82) - The directory or file cannot be set up<br/> 83) - INT 24 fails<br/> 84) - Memory space to handle this request unavailable<br/> 85) - Local device name already in use<br/> 86) - Specified network password incorrect<br/> 87) - Parameters incorrect<br/> 88) - Write error occurs over network<br/> 89) - System cannot start up another process at this time<br/> 100) - Another system signal lamp cannot be created. <br/> Other Win32 status codes may be viewed directly by using the command “net helpmsg” in the command-line mode.<br/>	The format of “net helpmsg” is as follows: <br/> NET HELPMSG message#<br/> Where, message# stands for Win32 status code. For examples: NET HELPMSG 64 will return “Specified network name no longer available”; NET HELPMSG 1727 will return “Remote process call fails and does not run”.
					</p>
				</li>
				<li>2. <b>c_ip</b>：IP address of the client accessing the server (Client IP address)
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with c_ip. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>http_x_forwarded_for</td>
							<td>c-ip</td>
							<td>c-ip</td>
							<td>c-ip</td>
						</tr>
					</table>
				</li>
				<li>3. <b>s_ip</b>: IP address of the server which generating log entries (IP address of server which recording log)
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with s_ip. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>upstream_addr</td>
							<td>s-ip</td>
							<td>s-ip</td>
							<td>s-ip</td>
						</tr>
					</table>
				</li>
				<li>4. <b>time</b>：Time stamp. It records the occurrence time of a log trigger behavior. Time stamp is a very important concept and dimension in statistics and processing (log generation time) in log analysis report and intelligent search.
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with time. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>time_loca</td>
							<td>time</td>
							<td>timestamp</td>
							<td>time</td>
						</tr>
					</table>
				</li>
				<li>5. <b>requste_time</b>：It refers to the time in millisecond spent in executing this operation. It is the time from when the server accepting the first byte of a user request to when all the response data are sent. It includes the time to receive request data, program response time, time to output response data.
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with request_time. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>request_time</td>
							<td>time-taken</td>
							<td>time-taken</td>
							<td>time-taken</td>
						</tr>
					</table>
				</li>
				<li>6. <b>app_server</b>：Application server provides the interface that a client can invoke and provides the server side with a full-functional reliable operating environment. For example, a database system is to management data and it also provide the environment for monitor and management, and system-level functions as affairs, safety, load balance, concurrence and so forth. It is unnecessary for users  to deal with concurrent locking issues of database tables, parsing of SQL sentences or optimization of index and other system-level functions; similarly, it is unnecessary for any invoker of server-side assemblies to process concurrent request, object creation, destruction, buffering, control component transaction and other system-level functions. </li>
				<li>7. <b>remote_user</b>：Unmapped user name string sent by a user. This name is the actually one sent by the user and corresponds to the name modified by the validation filter on the server. The user name of remote client  is used to record the name provided by the browser during identity certification. For example: if a user login Baidu on the user name “scq2099yt”, the remote_user is scq2099yt; if no one login, it will be recorded as blank or “-”; after receiving this field, the server will compare it with the user name field in the database, and if they are consistent, the user can login successfully, otherwise will be failed.
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with remote_user. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>remote_user</td>
							<td>username</td>
							<td>cs-username</td>
						</tr>
					</table>
				</li>
				<li>8. <b>c_method</b>：Client-side execution behavior such as GET, POST and other request behavior (recording the behavior  that user request for, for which request is from the server for resources or which request is from deliver resource to server, etc.).
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with c_method. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>request</td>
							<td>Not separately parsed as c_method because associated information is already included in the URI field</td>
							<td>request_mode</td>
							<td>cs-method</td>
						</tr>
					</table>
				</li>
				<li>9. <b>s_sitename</b>：Server site name, i.e., Internet service name and instance number when an event is running on the client side (which is the unique field of IIS log format, recording the name of service and instance running on client). </li>
				<li>10. <b>bytes</b>：It refers to the total bytes operated once by a user, including the bytes the user sends to the server and the server sends to the user (Note: Some logs may separate these types but CAMPASS will add them up for statistics).
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with bytes. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>bytes_sent</td>
							<td>cs-bytes+sc-bytes</td>
							<td>bytes</td>
							<td>cs-bytes+sc-bytes</td>
						</tr>
					</table>
				</li>
				<li>11. <b>http_referer</b>：Access referrer, standing for where this access request is skipped from (i.e. the previous page before a user enter the current page).
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with http_referer. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>http_referer</td>
							<td>referer</td>
							<td>cs(referer)</td>
						</tr>
					</table>
				</li>
				<li>12. <b>http_user_agent</b>：It records the user agent information, including which operating system the visitor is using (sometimes including version number), browser (including its version number sometimes), user preferences and other information. Note: If you find that this field contains operating system (browser) and/or browser (os), you may select the http_user_agent field.
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with http_user_agent. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>http_user_agent</td>
							<td>cs(user-agent)</td>
							<td>cs(user-agent)</td>
							<td>cs(user-agent)</td>
						</tr>
					</table>
				</li>
				<li>13. <b>sc_status</b>：Protocol status code (it is the status returned after the operation described by using HTTP or FTP terms, and it may display a status of the current visit (Success, Failure or other status)).
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with sc_status. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>status</td>
							<td>sc-status</td>
							<td>sc-status</td>
							<td>sc-status</td>
						</tr>
					</table>
				</li>
				<li>14. <b>s_port</b>：It is the transport-layer port for the server side to provide services (i.e. a port number connecting server service).
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with s_port. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs </td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>connection</td>
							<td>s-prot</td>
							<td>s-prot</td>
							<td>s-prot</td>
						</tr>
					</table>
				</li>
				<li>15. <b>URL</b>：URL is a character string over the Internet used to describe information resources, mainly used in various WWW client programs and server programs. The application of URL may use a uniform format to describe various information resources, including files, sever addresses and directories and so on.
					<br/> URL is composed of the following three parts:
					<br/> First part is the protocol (or service mode);
					<br/> Second part is the IP address of the host owning the resources (sometimes also including port number);
					<br/> Third part is the specific address of the host resource, such as directory, file name and so on.
					<br/> The first part is separated from the second part by“://”, and the second part is separated from the third part by “/”. The first and second parts are indispensable, while the third part may be omitted sometimes.
					<br/> In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with URL. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>Nginx</td>
							<td>Apache</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>URL</td>
							<td>URL</td>
							<td>Visit_URL</td>
							<td>cs-uri-stem</td>
						</tr>
					</table>
				</li>
				<li>16. <b>cookie</b>：t refers to the data stored in the local terminal of a user for some websites to identify the user and track the user sessions (often encrypted).
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with cookie. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs</td>
							<td>squid</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>request_cookie/response_cookie</td>
							<td>cookie</td>
						</tr>
					</table>
				</li>
				<li>17. <b>cs-host</b>：It is HTTP header on the client (host header), and a connector “-” standing for no such information (refers to the session before the data transmission between HTTP server and client (browser in general). Just like downloading a web pate, generally the browser give the server a information, and the server will return a HTTP header, and then the browser will continue to request for the web page data form the server according to the information given by the header.</li>
				<li>18. <b>version</b>：It records the version and version number of the protocol used on the client (recording the HTTP or FTP used by the user and the HTTP or FTP version number).
					<br/>In different types of logs, the contents in this field may be habitually named differently, but the information they refer to is consistent with version. For example:
					<table class="helptable" border="1">
						<tr>
							<td>Type of logs </td>
							<td>Nginx</td>
							<td>IIS</td>
						</tr>
						<tr>
							<td>Byname</td>
							<td>version</td>
							<td>cs-version</td>
						</tr>
					</table>
				</li>
				<li>19. <b>others</b>：If the information in a log can not be parsing in the rules above, it will be parsing as “others”.</li>
			</ul>
			<p class="line"></p>
		</div>
		<div class="part4">
			<h2 id="f4">IV. Contact us</h2>
			<p class="help1">For more product information or assistance, please contact our technical support staff:</p>
			<p class="help1">E-mail:support@open01.com</p>
			<p class="help1">Tel: 01082724800</p>
			
			<p class="help1">We will serve you wholeheartedly!</p>
			<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>
			<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>
			<br/><br/><br/><br/><br/><br/>
		</div>
	</div>
</div>
